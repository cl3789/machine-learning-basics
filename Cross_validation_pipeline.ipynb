{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c6cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold, KFold, cross_val_score,cross_validate\n",
    "\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, auc, RocCurveDisplay\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e778477",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load MNIST data\n",
    "digits = load_digits()\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "digit_label = digits.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8507e8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit label: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7bd0460220>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFIAAABWCAYAAABcvcGNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAADj0lEQVR4nO2cv2sUQRSAv+dJGpEEEhWiYgzY2JgiWNlYKOmSUrtUqfwDLJNCsIztIZI0YhewCP5ogm0inPgDlVw4MWnUInCdRJ7FnXgJt3uTuTeXu9z7IOR2Zmfn8TGzOzs7u6KqOO1z4qgDOC64SCNcpBEu0ggXaYSLNOJkyE4iMgU8AgrAY1V92GL/qDFVoVDIzBsdHW2aPjw8nFmmWq1m5pXL5fDAGlBVaZYurcaRIlIAvgK3gG1gHbirqp9yykSJHBoaysybn59vmj47O5tZZm1tLTNvZmYmKKaDZIkM6drXgU1V3VLV38AzYDoqimNMiMjzwPeG7e16mtNA0DkyBBGZA+asjtdrhIjcAS42bF+op+1DVYtAEeLPkb1MSNdeB66IyGURGQDuAM/ThtV7tGyRqronIveAl9SGP09U9WOKYJaWljLzpqebX98WFhYyy+Rd0fPy8uLIIugcqaqrwOqhj95H+J2NES7SCBdphIs0wkUaYXZnE8rY2FhmXtYQB2B5eblpetZkBuRPgkxMTGTmxeAt0ggXaYSLNMJFGuEijXCRRnR8+LO7uxtVLmZGJrauGLxFGuEijXCRRrhII1ykER2/altPFnQL3iKNcJFGuEgjXKQRLtIIF2lE6IrdClAF/gB7qjoZW2GpVIoqNzg42DQ99rlM3rOeGA4zjrypqr9Maz9GeNc2IlSkAq9E5G19QalzgNCufUNVd0TkLPBaRD6r6pvGHfp9xW5Qi1TVnfr/H8AKtQX6B/cpqupkOxeiXqalSBE5JSKn//0GbgMfUgfWa4S8ZzNOrRVC7VTwVFUftCgTtYY8772YLCqVSkxVuSt288h6zyZk6fMWcC2q1j7Chz9GuEgjXKQRLtIIF2lEy+FP1EETvGa8uLjYND1vhidviBM7C9XOa8ZOAC7SCBdphIs0wkUa4SKNSDX8+Ql8q2+OAN3wrMcijkuqeqZZRhKR+yoQ2eiGyd7UcXjXNsJFGtEJkcUO1BFC0jiSnyP7Be/aRiQTKSJTIvJFRDZF5H6qegJjqYjIexEpichGkkpU1fyP2veBysA4MAC8A66mqCswngowkrKOVC2y777wl0pkt33hL/napY6/HnJEtFy71C6pWmTQF/46RcjapXZJJbJrvvDXqbVLSbp2J7/wF8A5YEVE4P/apRfWlfidjRF+Z2OEizTCRRrhIo1wkUa4SCNcpBEu0oi/QeLsS1v4La8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Show one sample\n",
    "sample_ind = 10\n",
    "print(\"digit label:\",digit_label[sample_ind] )\n",
    "plt.figure(figsize = (1,1))\n",
    "plt.imshow(data[sample_ind].reshape(8,8), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554cf91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1437, 64)\n",
      "Test data shape: (360, 64)\n"
     ]
    }
   ],
   "source": [
    "## Train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, digit_label,\n",
    "                                                    test_size=0.2, ## use 20% data for test\n",
    "                                                    random_state=42, ## set random state for replication of experiment\n",
    "                                                    stratify=digit_label ## stratify data instances based on their labels\n",
    "                                                    )   \n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecbb3de",
   "metadata": {},
   "source": [
    "# Set up pipeline and gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e05154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize classifiers\n",
    "\n",
    "clf1 = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "clf2 = MLPClassifier(random_state=1)\n",
    "\n",
    "\n",
    "## Initialize pipeline for Decision Tree and MLP repectively\n",
    "pipe1 = Pipeline([('scaler', StandardScaler()),\n",
    "                  ('clf1', clf1)])\n",
    "\n",
    "pipe2 = Pipeline([('scaler', StandardScaler()),\n",
    "                  ('clf2', clf2)])\n",
    "\n",
    "\n",
    "## Setting up parameter grid\n",
    "\n",
    "# Define the range of hyperparameter to search from\n",
    "# The part can be change if you want to search other combinations of hyperparameters\n",
    "param_grid_decisiontree = [{'clf1__max_depth': list(range(1, 10)) + [None]}]\n",
    "\n",
    "param_grid_mlp = [{'clf2__hidden_layer_sizes': [(40,), (40,40)]}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1da64854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Decision Tree': GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=1, shuffle=True),\n",
      "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                                       ('clf1',\n",
      "                                        DecisionTreeClassifier(random_state=1))]),\n",
      "             n_jobs=-1,\n",
      "             param_grid=[{'clf1__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
      "                                              None]}],\n",
      "             refit='accuracy', scoring=['accuracy']), 'MLP': GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=1, shuffle=True),\n",
      "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                                       ('clf2',\n",
      "                                        MLPClassifier(random_state=1))]),\n",
      "             n_jobs=-1,\n",
      "             param_grid=[{'clf2__hidden_layer_sizes': [(40,), (40, 40)]}],\n",
      "             refit='accuracy', scoring=['accuracy'])}\n"
     ]
    }
   ],
   "source": [
    "# Setting up multiple GridSearchCV objects\n",
    "\n",
    "gridcvs = {} \n",
    "inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=1) # inner loop cross-validation with 4 folds\n",
    "\n",
    "for pgrid, est, name in zip((param_grid_decisiontree, param_grid_mlp),\n",
    "                            (pipe1, pipe2),\n",
    "                            ('Decision Tree', 'MLP')):\n",
    "    gcv = GridSearchCV(estimator=est,\n",
    "                       param_grid=pgrid,\n",
    "                       scoring = ['accuracy'], ## scoring metric can be also changed\n",
    "                       n_jobs=-1,\n",
    "                       cv=inner_cv,\n",
    "                       verbose=0,\n",
    "                       refit=\"accuracy\")\n",
    "    gridcvs[name] = gcv\n",
    "    \n",
    "print(gridcvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c19d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method: Decision Tree\n",
      "{'clf1__max_depth': None}\n",
      "\n",
      "\n",
      "{'clf1__max_depth': 9}\n",
      "\n",
      "\n",
      "{'clf1__max_depth': 8}\n",
      "\n",
      "\n",
      "outer loop accuracy 83.16% +/- 1.66\n",
      "outer loop AUC 91.07% +/- 0.98\n",
      "\n",
      "\n",
      "Current method: MLP\n",
      "{'clf2__hidden_layer_sizes': (40,)}\n",
      "\n",
      "\n",
      "{'clf2__hidden_layer_sizes': (40, 40)}\n",
      "\n",
      "\n",
      "{'clf2__hidden_layer_sizes': (40,)}\n",
      "\n",
      "\n",
      "outer loop accuracy 96.17% +/- 0.77\n",
      "outer loop AUC 99.85% +/- 0.09\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Define outer loop\n",
    "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "\n",
    "def nested_cross_val(features, labels, gridcvs):\n",
    "    \"\"\" nested cross validation to compare across ML methods.\n",
    "        features: the training dataset,\n",
    "        labels: the corresponding labels for the training data \"\"\"\n",
    "    for method, gridsearch in sorted(gridcvs.items()):\n",
    "        print(\"Current method:\",method)\n",
    "\n",
    "        scores = cross_validate(gridsearch, \n",
    "                                       X=features, \n",
    "                                       y=labels, \n",
    "                                       cv=outer_cv,\n",
    "                                       n_jobs=-1,\n",
    "                                       return_estimator = True,\n",
    "                                       scoring = ['accuracy', 'roc_auc_ovr'], ## roc_auc, f1 only works for binary class\n",
    "                                       error_score=\"raise\")\n",
    "\n",
    "        auc = scores['test_roc_auc_ovr']\n",
    "        accuracy = scores['test_accuracy']\n",
    "        estimators = scores['estimator']\n",
    "        \n",
    "        for i in estimators:\n",
    "            print(i.best_params_) # show the best parameter with highest prediction accuracy\n",
    "            print('\\n')\n",
    "        print('outer loop accuracy %.2f%% +/- %.2f' % \n",
    "              (accuracy.mean() * 100, accuracy.std() * 100))\n",
    "        print('outer loop AUC %.2f%% +/- %.2f' % \n",
    "              (auc.mean() * 100, auc.std() * 100))\n",
    "        ## Similarlly, you can also print out other scoring metrics\n",
    "        print('\\n')\n",
    "            \n",
    "\n",
    "nested_cross_val(X_train, y_train, gridcvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5284fcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the best model on the training set, and predict on the test set\n",
    "\n",
    "def run_test(train_features, train_labels, \n",
    "             test_features, test_labels, \n",
    "             model_name, paramters, folds):\n",
    "    \"\"\"Fit the model on the entire training set, and\n",
    "    test on the test set.\"\"\"\n",
    "    model_select = GridSearchCV(estimator=model_name,\n",
    "                                param_grid=paramters,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                cv=folds,\n",
    "                                verbose=3, # display folds in computation steps\n",
    "                                refit=True # need to be True in order to return best_estimator_ \n",
    "                               )\n",
    "\n",
    "    ## Fit the model on the entire training dataset\n",
    "    model_select.fit(train_features, train_labels)\n",
    "    \n",
    "    ## grad the model with the set of hyperparameters that gives the best mean prediction accuracy across cross-validation \n",
    "    best_model = model_select.best_estimator_\n",
    "    \n",
    "        \n",
    "    train_acc = accuracy_score(y_true=train_labels, y_pred=best_model.predict(train_features))\n",
    "    test_acc = accuracy_score(y_true=test_labels, y_pred=best_model.predict(test_features))\n",
    "\n",
    "    print('Accuracy %.2f%% (average over k-fold CV test folds)' %\n",
    "          (100 * model_select.best_score_))\n",
    "    print('Best Parameters: %s' % model_select.best_params_)\n",
    "\n",
    "    print('Best Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "    print('Test Accuracy: %.2f%%' % (100 * test_acc))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c7bdef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Accuracy 97.36% (average over k-fold CV test folds)\n",
      "Best Parameters: {'alpha': 0.1, 'hidden_layer_sizes': (100,)}\n",
      "Best Training Accuracy: 100.00%\n",
      "Test Accuracy: 83.89%\n"
     ]
    }
   ],
   "source": [
    "## Standardize the test set\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=4, shuffle=True, random_state=1) \n",
    "\n",
    "\n",
    "## Set up range of hyperparameters to search on MLP\n",
    "param_grid_mlp =  [{'alpha': [0.1, 0.01, 0.01, 0.001, 0.0001],\n",
    "                    'hidden_layer_sizes': [(40,), (100,)]}]\n",
    "run_test(X_train, y_train, X_test, y_test, clf2, param_grid_mlp, folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9c682",
   "metadata": {},
   "source": [
    "# K-fold with GridSearch\n",
    "Example from sklearn: https://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#sphx-glr-auto-examples-exercises-plot-cv-diabetes-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a8a6996",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442,)\n",
      "[1.00000000e-04 1.32035178e-04 1.74332882e-04 2.30180731e-04\n",
      " 3.03919538e-04 4.01280703e-04 5.29831691e-04 6.99564216e-04\n",
      " 9.23670857e-04 1.21957046e-03 1.61026203e-03 2.12611233e-03\n",
      " 2.80721620e-03 3.70651291e-03 4.89390092e-03 6.46167079e-03\n",
      " 8.53167852e-03 1.12648169e-02 1.48735211e-02 1.96382800e-02\n",
      " 2.59294380e-02 3.42359796e-02 4.52035366e-02 5.96845700e-02\n",
      " 7.88046282e-02 1.04049831e-01 1.37382380e-01 1.81393069e-01\n",
      " 2.39502662e-01 3.16227766e-01]\n",
      "Show the total number of model being searched: 30\n",
      "mean_test_score for each searched model:\n",
      " [0.42685499 0.42692161 0.42700942 0.42712511 0.4272774  0.42747775\n",
      " 0.42774094 0.42805203 0.42842188 0.42890288 0.42952759 0.43033467\n",
      " 0.43136937 0.43268146 0.43432033 0.43621305 0.43805655 0.43990997\n",
      " 0.44049206 0.44117891 0.44195759 0.44246364 0.44273332 0.44241731\n",
      " 0.44121351 0.43833    0.43338557 0.42488328 0.41250565 0.39121017]\n",
      "check whether this confirms the sklearn returned results:\n",
      " True\n",
      "[0.13806647 0.40286624 0.55833295 0.51373671 0.37738963 0.57073794]\n",
      "[0.13807169 0.40295158 0.55840152 0.5139635  0.37739806 0.57074335]\n",
      "[0.13807855 0.40306411 0.55849192 0.51426237 0.37740912 0.57075045]\n",
      "[0.13808763 0.40321245 0.55861099 0.51465598 0.37742371 0.57075987]\n",
      "[0.13809956 0.40340798 0.55876783 0.51517375 0.37744294 0.5707723 ]\n",
      "[0.13811534 0.40366543 0.5589741  0.51585451 0.37746842 0.57078869]\n",
      "[0.13813612 0.40400409 0.55924531 0.51674799 0.37750182 0.57081029]\n",
      "[0.13816337 0.40444899 0.55939632 0.51791875 0.377546   0.57083874]\n",
      "[0.13819931 0.40503307 0.55937106 0.51944788 0.37760382 0.57087614]\n",
      "[0.13824647 0.40579747 0.5593375  0.52143913 0.37768009 0.57091659]\n",
      "[0.13830826 0.40679523 0.55929286 0.52401978 0.37778008 0.57096932]\n",
      "[0.13838925 0.40809334 0.55923315 0.5273423  0.37791078 0.57103918]\n",
      "[0.13849471 0.4097738  0.55915309 0.53158208 0.37808186 0.57113067]\n",
      "[0.13863174 0.41193307 0.55904526 0.53692387 0.37830474 0.57125008]\n",
      "[0.13880846 0.41468065 0.55889954 0.54353434 0.37859294 0.57140604]\n",
      "[0.13903582 0.41749104 0.5586946  0.55149317 0.37895621 0.57160746]\n",
      "[0.13932561 0.4185611  0.55852251 0.56065299 0.3794101  0.57186698]\n",
      "[0.13968696 0.41993381 0.55855743 0.56909424 0.37999056 0.5721968 ]\n",
      "[0.14008207 0.42167736 0.55855022 0.56947596 0.38055535 0.57261143]\n",
      "[0.14134143 0.42385934 0.55846623 0.56883435 0.38145502 0.57311709]\n",
      "[0.14300625 0.42653313 0.55822423 0.5677076  0.38255488 0.57371947]\n",
      "[0.14514304 0.42969955 0.55767677 0.56526121 0.38259798 0.57440328]\n",
      "[0.14732313 0.43324102 0.5565318  0.56194379 0.38227404 0.57508615]\n",
      "[0.14983422 0.43680483 0.55205736 0.55740777 0.38272218 0.5756775 ]\n",
      "[0.15284387 0.43950036 0.54528555 0.55114856 0.38325818 0.57524458]\n",
      "[0.15628363 0.44368842 0.5316793  0.54241682 0.38313    0.57278185]\n",
      "[0.1598979  0.44767372 0.51289655 0.530078   0.38152733 0.56823992]\n",
      "[0.16574681 0.44909275 0.48511482 0.512378   0.37709283 0.5598745 ]\n",
      "[0.16979998 0.44856649 0.45754374 0.48655279 0.36807079 0.54450013]\n",
      "[0.16991222 0.44072408 0.41822973 0.44817425 0.35046012 0.51976061]\n",
      "check whether this confirms the GridSearchCV:\n",
      " True\n"
     ]
    }
   ],
   "source": [
    "# Example from sklearn: https://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#sphx-glr-auto-examples-exercises-plot-cv-diabetes-py\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold, KFold, cross_val_score,cross_validate\n",
    "\n",
    "X, y = datasets.load_diabetes(return_X_y=True)\n",
    "print(y.shape)\n",
    "X = X[:150] # keep first 150 rows\n",
    "y = y[:150] # keep first 150 rows\n",
    "\n",
    "lasso = Lasso(random_state=0, max_iter=10000)\n",
    "alphas = np.logspace(-4, -0.5, 30)\n",
    "\n",
    "print(alphas)\n",
    "\n",
    "num_of_model = alphas.shape[0]\n",
    "\n",
    "print(\"Show the total number of model being searched:\",num_of_model)\n",
    "\n",
    "tuned_parameters = [{\"alpha\": alphas}]\n",
    "n_folds = KFold(n_splits=6, shuffle=True, random_state=1)\n",
    "\n",
    "clf = GridSearchCV(lasso, tuned_parameters, cv=n_folds, refit=False)\n",
    "clf.fit(X, y)\n",
    "\n",
    "## Compute mean test score of each model across k-folds\n",
    "scores = clf.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf.cv_results_[\"std_test_score\"]\n",
    "\n",
    "\n",
    "## Manually compute the mean test score across k-folds\n",
    "mean_test_scores = []\n",
    "for model_num in range(num_of_model):\n",
    "    #print(\"current model:\", model_num)\n",
    "    all_score = []\n",
    "    for fold in range(n_folds.n_splits):\n",
    "        name = \"split\"+str(fold)+\"_test_score\"\n",
    "        test_score_fold = clf.cv_results_[name][model_num] # get the test score of the \n",
    "        all_score.append(test_score_fold)\n",
    "        #print(\"Scores of the model fit in k-fold: \",all_score)\n",
    "    mean_score = sum(all_score)/len(all_score) # compute the average score across k-fold for each searched model\n",
    "    mean_test_scores.append(mean_score)\n",
    "    \n",
    "mean_test_scores = np.array(mean_test_scores)\n",
    "print(\"mean_test_score for each searched model:\\n\",mean_test_scores)\n",
    "\n",
    "## check that this is equivalent to returned values from clf.cv_results_[\"mean_test_score\"]\n",
    "print(\"check whether this confirms the sklearn returned results:\\n\",np.array_equal(mean_test_scores, scores))\n",
    "\n",
    "\n",
    "## Instead of using GridSearchCV, we can manually check the performance of each searched model in the test folds.\n",
    "models_test_mean_cv = []\n",
    "for alpha in alphas:\n",
    "    # We manually loop through each possible \"alpha\" \n",
    "    current_model = Lasso(random_state=0, max_iter=10000, alpha = alpha) # define the current model's hyperparameters\n",
    "    test_score = cross_validate(current_model, X, y, cv=n_folds)['test_score'] # cross validate across k held-out folds\n",
    "    print(test_score)\n",
    "    models_test_mean_cv.append(test_score.mean()) # for each model, compute the mean test_score across k held-out folds\n",
    "models_test_mean_cv = np.array(models_test_mean_cv) \n",
    "\n",
    "print(\"check whether this confirms the GridSearchCV:\\n\",np.array_equal(models_test_mean_cv, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3f0d01",
   "metadata": {},
   "source": [
    "# Preprocessing for data with Mixed dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5383a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch \"titanic dataset\". \n",
    "X_titanic, y_titanic = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92b8f120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 13 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   pclass     1309 non-null   float64 \n",
      " 1   name       1309 non-null   object  \n",
      " 2   sex        1309 non-null   category\n",
      " 3   age        1046 non-null   float64 \n",
      " 4   sibsp      1309 non-null   float64 \n",
      " 5   parch      1309 non-null   float64 \n",
      " 6   ticket     1309 non-null   object  \n",
      " 7   fare       1308 non-null   float64 \n",
      " 8   cabin      295 non-null    object  \n",
      " 9   embarked   1307 non-null   category\n",
      " 10  boat       486 non-null    object  \n",
      " 11  body       121 non-null    float64 \n",
      " 12  home.dest  745 non-null    object  \n",
      "dtypes: category(2), float64(6), object(5)\n",
      "memory usage: 115.4+ KB\n",
      "   pclass                                             name     sex      age  \\\n",
      "0     1.0                    Allen, Miss. Elisabeth Walton  female  29.0000   \n",
      "1     1.0                   Allison, Master. Hudson Trevor    male   0.9167   \n",
      "2     1.0                     Allison, Miss. Helen Loraine  female   2.0000   \n",
      "3     1.0             Allison, Mr. Hudson Joshua Creighton    male  30.0000   \n",
      "4     1.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000   \n",
      "\n",
      "   sibsp  parch  ticket      fare    cabin embarked  boat   body  \\\n",
      "0    0.0    0.0   24160  211.3375       B5        S     2    NaN   \n",
      "1    1.0    2.0  113781  151.5500  C22 C26        S    11    NaN   \n",
      "2    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
      "3    1.0    2.0  113781  151.5500  C22 C26        S  None  135.0   \n",
      "4    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
      "\n",
      "                         home.dest  \n",
      "0                     St Louis, MO  \n",
      "1  Montreal, PQ / Chesterville, ON  \n",
      "2  Montreal, PQ / Chesterville, ON  \n",
      "3  Montreal, PQ / Chesterville, ON  \n",
      "4  Montreal, PQ / Chesterville, ON  \n",
      "Shape of dataset: (1309, 13)\n"
     ]
    }
   ],
   "source": [
    "## Check the data type of each column\n",
    "X_titanic.info()\n",
    "print(X_titanic.head())\n",
    "print(\"Shape of dataset:\",X_titanic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee36831f",
   "metadata": {},
   "source": [
    "We create the preprocessing pipelines for both numeric and categorical data. Here, we can use ColumnTransformer. This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer.\n",
    "(noted in:https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5d4c0",
   "metadata": {},
   "source": [
    "Here, we will pick 5 features as the predictors: \n",
    "Numerical data: \"age\", \"fare\";\n",
    "Categorical data: \"embarked\", \"sex\", \"pclass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c4dbd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply different preprocessing and feature extraction pipelines to different subsets of features.\n",
    "## https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "\n",
    "\n",
    "## For \"numeric_features\" and \"categorical_features\", you can add more features if you want. Here, I used 5 features in total.\n",
    "\n",
    "numeric_features = [\"age\", \"fare\"] # columns that are numeric\n",
    "numeric_transformer = Pipeline(\n",
    "    ## Note that there are missing data in some columns, e.g., body\n",
    "    steps=[(\"replace_missing\", SimpleImputer(strategy=\"median\")), # Replace missing values using a descriptive statistic (e.g. here is median) along each column\n",
    "           (\"scaler\", StandardScaler()) # standardize numerical values\n",
    "          ] \n",
    ")\n",
    "\n",
    "categorical_features = [\"sex\", \"embarked\", \"pclass\"] # columns that are categorical\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\") # set up one-hot encoding\n",
    "\n",
    "\n",
    "## Define the steps to preprocess the original data, with the customized transformation methods\n",
    "preprocessor = ColumnTransformer(\n",
    "    ## Note that you can change the names in transformater \"numerical\" to others. Totally depends on your naming\n",
    "    transformers=[\n",
    "        (\"numerical\", numeric_transformer, numeric_features), # Transform numeric data\n",
    "        (\"categorical\", categorical_transformer, categorical_features), # Transform categorical data through one-hot encoding\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2346c8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;replace_missing&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;fare&#x27;]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;sex&#x27;, &#x27;embarked&#x27;, &#x27;pclass&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;replace_missing&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;fare&#x27;]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;sex&#x27;, &#x27;embarked&#x27;, &#x27;pclass&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;fare&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sex&#x27;, &#x27;embarked&#x27;, &#x27;pclass&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('numerical',\n",
       "                                 Pipeline(steps=[('replace_missing',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['age', 'fare']),\n",
       "                                ('categorical',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['sex', 'embarked', 'pclass'])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check out the steps in customoized ColumnTransformer\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f734a6b",
   "metadata": {},
   "source": [
    "In the pipeline, instead of using \"StandardScaler()\" to standard the entire training feature, we can applied the customized \"preprocessor\", which transform the numeric and categorical data separately, and concatenate them to a single feature space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "270d0afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in sex column: ['female', 'male']\n",
      "Categories (2, object): ['female', 'male']\n",
      "Unique values in pclass column: [1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "## The \"sex\" column has two unique values\n",
    "print(\"Unique values in sex column:\", X_titanic[\"sex\"].unique())\n",
    "\n",
    "print(\"Unique values in pclass column:\", X_titanic[\"pclass\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a7c93e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03900549,  3.44258413,  1.        ,  0.        ,  0.        ,\n",
       "        0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the first row of the transformed data\n",
    "preprocessor.fit_transform(X_titanic)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f57a79",
   "metadata": {},
   "source": [
    "Note, -0.03900549 is the standardized \"age\", 3.44258413 is the standardized \"fare\", 3rd and 4th columns together is the one-hot encoding of \"sex\". [1, 0] means the person is female. Last three columns together is the one-hot encoding for \"pclass\". [1., 0., 0.] means \"pclass\" is \"1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a2592c",
   "metadata": {},
   "source": [
    "Now, setting up the model. Here, for simplicity, I will use simple cross-validation to find the best hyperparamters, by fitting on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "351e0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up RandomForestClassifier\n",
    "chosed_classifier = RandomForestClassifier(random_state = 1)\n",
    "\n",
    "\n",
    "## Set up pipeline to train the model\n",
    "pipe3 = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), # first, the features from X_titanic will be preprocessed and transformed via customized ColumnTransformer \n",
    "           (\"clf3\", chosed_classifier) # fitting with desired model\n",
    "          ])\n",
    "\n",
    "## Set up folds for cross-validation\n",
    "folds_titanic = StratifiedKFold(n_splits=3, shuffle=True, random_state=1) \n",
    "\n",
    "\n",
    "## Set up the range of parameters to search from\n",
    "param_grid_randomforest = [{'clf3__max_depth': list(range(1, 100,10)), \n",
    "                            'clf3__n_estimators': list(range(1, 100,5))\n",
    "                           }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d517ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training feature:  (1047, 13)\n",
      "Note, the data transformation will happen when running the model fitting pipeline (pipe3)\n",
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n",
      "Accuracy 79.37% (average over k-fold CV test folds)\n",
      "Best Parameters: {'clf3__max_depth': 11, 'clf3__n_estimators': 31}\n",
      "Best Training Accuracy: 94.08%\n",
      "Test Accuracy: 80.53%\n"
     ]
    }
   ],
   "source": [
    "## Train-test split of titanic data\n",
    "X_train_tt, X_test_tt, y_train_tt, y_test_tt = train_test_split(X_titanic, y_titanic, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Shape of training feature: \", X_train_tt.shape)\n",
    "print(\"Note, the data transformation will happen when running the model fitting pipeline (pipe3)\")\n",
    "\n",
    "## Please check \"run_test\" define above.\n",
    "run_test(X_train_tt, y_train_tt, \n",
    "         X_test_tt, y_test_tt, \n",
    "         pipe3, param_grid_randomforest, folds_titanic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
